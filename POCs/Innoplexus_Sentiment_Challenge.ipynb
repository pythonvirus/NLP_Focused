{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Disable Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP functionalities and libraries\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Classification evaluation\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, \n",
    "                             recall_score, f1_score)\n",
    "\n",
    "# Word Cloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Others\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Flatten, Dropout, Activation, Input, Dense, concatenate, LSTM, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "RANDOM_SEED = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
       "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
       "      <td>I can completely understand why you’d want to ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
       "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
       "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
       "      <td>ocrevus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
       "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0   \n",
       "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4   \n",
       "2  fe809672251f6bd0d986e00380f48d047c7e7b76   \n",
       "3  bd22104dfa9ec80db4099523e03fae7a52735eb6   \n",
       "4  b227688381f9b25e5b65109dd00f7f895e838249   \n",
       "\n",
       "                                                text        drug  sentiment  \n",
       "0  Autoimmune diseases tend to come in clusters. ...     gilenya          2  \n",
       "1  I can completely understand why you’d want to ...     gilenya          2  \n",
       "2  Interesting that it only targets S1P-1/5 recep...  fingolimod          2  \n",
       "3  Very interesting, grand merci. Now I wonder wh...     ocrevus          2  \n",
       "4  Hi everybody, My latest MRI results for Brain ...     gilenya          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>On fingolimod and have been since December 201...</td>\n",
       "      <td>fingolimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
       "      <td>humira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
       "      <td>tagrisso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
       "      <td>stelara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08   \n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a   \n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7   \n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae   \n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f   \n",
       "\n",
       "                                                text        drug  \n",
       "0  256 (previously stable on natalizumab), with 5...  fingolimod  \n",
       "1  On fingolimod and have been since December 201...  fingolimod  \n",
       "2  Apparently it's shingles! :-/ I do have a few ...      humira  \n",
       "3  If the Docetaxel doing once a week x3 weeks th...    tagrisso  \n",
       "4  CC, Stelara worked in a matter of days for me....     stelara  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5279, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2924, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['drug'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['drug'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_data['drug'].unique()).intersection(set(test_data['drug'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "drug_le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_le.fit(train_data['drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dict = dict(zip(drug_le.classes_, drug_le.transform(drug_le.classes_)))\n",
    "train_data['drug_enc'] = train_data['drug'].map(drug_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['drug_enc'] = test_data['drug'].map(drug_dict).fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy_matrix = np.zeros((train_data.shape[0],len(drug_le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummy_matrix = np.zeros((train_data.shape[0],len(drug_le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_data.shape[0]):\n",
    "    if train_data['drug'][i] in drug_dict:\n",
    "        train_dummy_matrix[i][drug_dict[train_data['drug'][i]]] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_data.shape[0]):\n",
    "    if test_data['drug'][i] in drug_dict:\n",
    "        test_dummy_matrix[i][drug_dict[test_data['drug'][i]]] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,:!./\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" is \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"(a-z)(\\))\", r\"(a-z) \", text)\n",
    "    text = re.sub(r\"(\\()(a-z)\", r\" (a-z)\", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    ## Lemmatization\n",
    "    text = text.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmed_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(lemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the above function to train\n",
    "train_data['Clean_text'] = train_data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the above function to train\n",
    "test_data['Clean_text'] = test_data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>drug_enc</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>35</td>\n",
       "      <td>256 previously stable natalizumab 55 switching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>On fingolimod and have been since December 201...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>35</td>\n",
       "      <td>fingolimod since december 2015; way describe b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
       "      <td>humira</td>\n",
       "      <td>43</td>\n",
       "      <td>apparently shingle ! : - / red spot left breas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
       "      <td>tagrisso</td>\n",
       "      <td>88</td>\n",
       "      <td>docetaxel week week week claim le harsh effica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
       "      <td>stelara</td>\n",
       "      <td>86</td>\n",
       "      <td>cc stelara worked matter day me willing jump h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08   \n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a   \n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7   \n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae   \n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f   \n",
       "\n",
       "                                                text        drug drug_enc  \\\n",
       "0  256 (previously stable on natalizumab), with 5...  fingolimod       35   \n",
       "1  On fingolimod and have been since December 201...  fingolimod       35   \n",
       "2  Apparently it's shingles! :-/ I do have a few ...      humira       43   \n",
       "3  If the Docetaxel doing once a week x3 weeks th...    tagrisso       88   \n",
       "4  CC, Stelara worked in a matter of days for me....     stelara       86   \n",
       "\n",
       "                                          Clean_text  \n",
       "0  256 previously stable natalizumab 55 switching...  \n",
       "1  fingolimod since december 2015; way describe b...  \n",
       "2  apparently shingle ! : - / red spot left breas...  \n",
       "3  docetaxel week week week claim le harsh effica...  \n",
       "4  cc stelara worked matter day me willing jump h...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>drug_enc</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
       "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>autoimmune disease tend come cluster gilenya f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
       "      <td>I can completely understand why you’d want to ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>completely understand you d want try it but re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
       "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>interesting target s1p - 1/5 receptor rather 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
       "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
       "      <td>ocrevus</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>interesting grand merci wonder lemtrada ocrevu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
       "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>everybody latest mri result brain cervical cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0   \n",
       "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4   \n",
       "2  fe809672251f6bd0d986e00380f48d047c7e7b76   \n",
       "3  bd22104dfa9ec80db4099523e03fae7a52735eb6   \n",
       "4  b227688381f9b25e5b65109dd00f7f895e838249   \n",
       "\n",
       "                                                text        drug  sentiment  \\\n",
       "0  Autoimmune diseases tend to come in clusters. ...     gilenya          2   \n",
       "1  I can completely understand why you’d want to ...     gilenya          2   \n",
       "2  Interesting that it only targets S1P-1/5 recep...  fingolimod          2   \n",
       "3  Very interesting, grand merci. Now I wonder wh...     ocrevus          2   \n",
       "4  Hi everybody, My latest MRI results for Brain ...     gilenya          1   \n",
       "\n",
       "   drug_enc                                         Clean_text  \n",
       "0        38  autoimmune disease tend come cluster gilenya f...  \n",
       "1        38  completely understand you d want try it but re...  \n",
       "2        35  interesting target s1p - 1/5 receptor rather 1...  \n",
       "3        64  interesting grand merci wonder lemtrada ocrevu...  \n",
       "4        38  everybody latest mri result brain cervical cor...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y = pd.get_dummies(train_data['sentiment']).values\n",
    "dummy_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test, drug_train, drug_test = train_test_split(train_data['Clean_text'].values,\n",
    "                                                                                 dummy_y,\n",
    "                                                                                 train_dummy_matrix,\n",
    "                                                                                 test_size = 0.25,\n",
    "                                                                                 random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "MAXLEN = 100\n",
    "embedding_size = 32\n",
    "op_units = train_data['sentiment'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20229  1373  3343 ...     0     0     0]\n",
      " [  615    27    55 ...     0     0     0]\n",
      " [  205  9892   406 ...     0     0     0]\n",
      " ...\n",
      " [  280   247   124 ...     0     0     0]\n",
      " [   15 12391   934 ...     0     0     0]\n",
      " [  386    25  7417 ...  3408   590   751]]\n"
     ]
    }
   ],
   "source": [
    "trainsequences = tokenizer.texts_to_sequences(text_train)\n",
    "trainseqs = pad_sequences(trainsequences, maxlen=MAXLEN, padding='post')\n",
    "print(trainseqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsequences = tokenizer.texts_to_sequences(text_test)\n",
    "testseqs = pad_sequences(testsequences, maxlen=MAXLEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    f1_score\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, \n",
    "                    embedding_size, \n",
    "                    input_length=MAXLEN))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(op_units, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adamax', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3959 samples, validate on 1320 samples\n",
      "Epoch 1/10\n",
      "3959/3959 [==============================] - 5s 1ms/step - loss: 0.8499 - acc: 0.7131 - val_loss: 0.7709 - val_acc: 0.7220\n",
      "Epoch 2/10\n",
      "3959/3959 [==============================] - 3s 789us/step - loss: 0.7155 - acc: 0.7254 - val_loss: 0.7550 - val_acc: 0.7220\n",
      "Epoch 3/10\n",
      "3959/3959 [==============================] - 3s 795us/step - loss: 0.6459 - acc: 0.7257 - val_loss: 0.7436 - val_acc: 0.7220\n",
      "Epoch 4/10\n",
      "3959/3959 [==============================] - 3s 784us/step - loss: 0.5611 - acc: 0.7477 - val_loss: 0.7365 - val_acc: 0.7265\n",
      "Epoch 5/10\n",
      "3959/3959 [==============================] - 3s 805us/step - loss: 0.4690 - acc: 0.8065 - val_loss: 0.7299 - val_acc: 0.7303\n",
      "Epoch 6/10\n",
      "3959/3959 [==============================] - 3s 804us/step - loss: 0.3802 - acc: 0.8626 - val_loss: 0.7353 - val_acc: 0.7288\n",
      "Epoch 7/10\n",
      "3959/3959 [==============================] - 3s 818us/step - loss: 0.3004 - acc: 0.9131 - val_loss: 0.7462 - val_acc: 0.7250\n",
      "Epoch 8/10\n",
      "3959/3959 [==============================] - 3s 842us/step - loss: 0.2346 - acc: 0.9487 - val_loss: 0.7594 - val_acc: 0.7227\n",
      "Epoch 9/10\n",
      "3959/3959 [==============================] - 3s 822us/step - loss: 0.1824 - acc: 0.9651 - val_loss: 0.7741 - val_acc: 0.7189\n",
      "Epoch 10/10\n",
      "3959/3959 [==============================] - 3s 829us/step - loss: 0.1420 - acc: 0.9768 - val_loss: 0.7911 - val_acc: 0.7189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feae2f573c8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(trainseqs, \n",
    "          y_train, \n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(testseqs,y_test),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_embeddings = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34001, 32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsequences = tokenizer.texts_to_sequences(test_data['Clean_text'].values)\n",
    "valseqs = pad_sequences(valsequences, maxlen=MAXLEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(valseqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>drug_enc</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>35</td>\n",
       "      <td>256 previously stable natalizumab 55 switching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>On fingolimod and have been since December 201...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>35</td>\n",
       "      <td>fingolimod since december 2015; way describe b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
       "      <td>humira</td>\n",
       "      <td>43</td>\n",
       "      <td>apparently shingle ! : - / red spot left breas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
       "      <td>tagrisso</td>\n",
       "      <td>88</td>\n",
       "      <td>docetaxel week week week claim le harsh effica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
       "      <td>stelara</td>\n",
       "      <td>86</td>\n",
       "      <td>cc stelara worked matter day me willing jump h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08   \n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a   \n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7   \n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae   \n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f   \n",
       "\n",
       "                                                text        drug drug_enc  \\\n",
       "0  256 (previously stable on natalizumab), with 5...  fingolimod       35   \n",
       "1  On fingolimod and have been since December 201...  fingolimod       35   \n",
       "2  Apparently it's shingles! :-/ I do have a few ...      humira       43   \n",
       "3  If the Docetaxel doing once a week x3 weeks th...    tagrisso       88   \n",
       "4  CC, Stelara worked in a matter of days for me....     stelara       86   \n",
       "\n",
       "                                          Clean_text  \n",
       "0  256 previously stable natalizumab 55 switching...  \n",
       "1  fingolimod since december 2015; way describe b...  \n",
       "2  apparently shingle ! : - / red spot left breas...  \n",
       "3  docetaxel week week week claim le harsh effica...  \n",
       "4  cc stelara worked matter day me willing jump h...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.concat([test_data['unique_hash'], \n",
    "                          pd.DataFrame(y_pred, columns=['sentiment'])],\n",
    "                         axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(r'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  sentiment\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08          2\n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a          2\n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7          2\n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae          2\n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f          2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
